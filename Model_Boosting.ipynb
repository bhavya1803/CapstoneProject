{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport torch\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms as T # for simplifying the transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split\nfrom torchvision import models\n## Now, we import timm, torchvision image models\n!pip install timm # kaggle doesnt have it installed by default\nimport timm\nfrom timm.loss import LabelSmoothingCrossEntropy # This is better than normal nn.CrossEntropyLoss\n# remove warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport sys\nfrom tqdm import tqdm\nimport time\nimport copy\nimport sklearn.metrics\nfrom sklearn.metrics import confusion_matrix\n!pip install oulumetrics\nimport oulumetrics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2023-03-09T06:32:38.954731Z","iopub.execute_input":"2023-03-09T06:32:38.955348Z","iopub.status.idle":"2023-03-09T06:33:01.136513Z","shell.execute_reply.started":"2023-03-09T06:32:38.955247Z","shell.execute_reply":"2023-03-09T06:33:01.135595Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n     |████████████████████████████████| 549 kB 3.9 MB/s            \n\u001b[?25hRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.1.2)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.9.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.10.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (3.10.0.2)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.3.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.25.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.8.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.62.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.19.5)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.2.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.6.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2021.10.8)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.10)\nInstalling collected packages: timm\nSuccessfully installed timm-0.6.12\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting oulumetrics\n  Downloading oulumetrics-0.1.tar.gz (1.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: oulumetrics\n  Building wheel for oulumetrics (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for oulumetrics: filename=oulumetrics-0.1-py3-none-any.whl size=2459 sha256=d2af96df8800867cc42c38019bd32356cee3616026e409e3852b944a95770b5b\n  Stored in directory: /root/.cache/pip/wheels/7f/20/61/c35d3f8bc5bd6f14bf745850cfd35ef096ee31b26afc861fed\nSuccessfully built oulumetrics\nInstalling collected packages: oulumetrics\nSuccessfully installed oulumetrics-0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras\n!pip install tensorflow-addons\n!pip install gdown\n\n!gdown --id 1hnKzb1cit2dePWwfRXmNG2kxCQS-oGJy\n!gdown --id 1BPI4EPPknI5FQ2t-MILqLI1bVWvf0D2U\n\n!unzip -q Protocol1_new\n!unzip -q undersampled_protocol1\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-03-09T06:33:01.139191Z","iopub.execute_input":"2023-03-09T06:33:01.139500Z","iopub.status.idle":"2023-03-09T06:33:50.178740Z","shell.execute_reply.started":"2023-03-09T06:33:01.139460Z","shell.execute_reply":"2023-03-09T06:33:50.177685Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (2.6.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.7/site-packages (0.14.0)\nRequirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons) (2.13.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting gdown\n  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.62.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.3.2)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.7)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.10)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.6.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n/opt/conda/lib/python3.7/site-packages/gdown/cli.py:125: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  category=FutureWarning,\nDownloading...\nFrom: https://drive.google.com/uc?id=1hnKzb1cit2dePWwfRXmNG2kxCQS-oGJy\nTo: /kaggle/working/Protocol1_new.zip\n100%|████████████████████████████████████████| 594M/594M [00:06<00:00, 85.2MB/s]\n/opt/conda/lib/python3.7/site-packages/gdown/cli.py:125: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  category=FutureWarning,\nDownloading...\nFrom: https://drive.google.com/uc?id=1BPI4EPPknI5FQ2t-MILqLI1bVWvf0D2U\nTo: /kaggle/working/undersampled_protocol1.zip\n100%|████████████████████████████████████████| 212M/212M [00:02<00:00, 87.5MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_classes(data_dir):\n    all_data = datasets.ImageFolder(data_dir)\n    return all_data.classes","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.180779Z","iopub.execute_input":"2023-03-09T06:33:50.181082Z","iopub.status.idle":"2023-03-09T06:33:50.186383Z","shell.execute_reply.started":"2023-03-09T06:33:50.181039Z","shell.execute_reply":"2023-03-09T06:33:50.185675Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_data_loaders(data_dir, batch_size, train = False):\n    if train:\n        #train\n        transform = T.Compose([\n            T.RandomHorizontalFlip(),\n            T.RandomVerticalFlip(),\n#             T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.25),\n            T.Resize(256),\n            T.CenterCrop(224),\n            T.ToTensor(),\n            T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet means\n            T.RandomErasing(p=0.20, value='random')\n        ])\n        train_data = datasets.ImageFolder('/kaggle/working/undersampled_protocol1/train_undersampled', transform = transform)\n        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        return train_loader, len(train_data)\n    else:\n        # val/test\n        transform = T.Compose([ # We dont need augmentation for test transforms\n            T.Resize(256),\n            T.CenterCrop(224),\n            T.ToTensor(),\n            T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet means\n        ])\n        val_data = datasets.ImageFolder(os.path.join(data_dir, \"dev/\"), transform=transform)\n        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        return val_loader, test_loader, len(val_data), len(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.188835Z","iopub.execute_input":"2023-03-09T06:33:50.189299Z","iopub.status.idle":"2023-03-09T06:33:50.198508Z","shell.execute_reply.started":"2023-03-09T06:33:50.189263Z","shell.execute_reply":"2023-03-09T06:33:50.197602Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset_path = \"/kaggle/working/Protocol1_new/Protocol1_seperated/\"","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.200065Z","iopub.execute_input":"2023-03-09T06:33:50.200325Z","iopub.status.idle":"2023-03-09T06:33:50.210208Z","shell.execute_reply.started":"2023-03-09T06:33:50.200290Z","shell.execute_reply":"2023-03-09T06:33:50.209438Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"(train_loader, train_data_len) = get_data_loaders(dataset_path, batch_size=16, train=True)\n(dev_loader, test_loader, dev_data_len, test_data_len) = get_data_loaders(dataset_path,batch_size=16, train=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.211675Z","iopub.execute_input":"2023-03-09T06:33:50.212058Z","iopub.status.idle":"2023-03-09T06:33:50.328399Z","shell.execute_reply.started":"2023-03-09T06:33:50.212023Z","shell.execute_reply":"2023-03-09T06:33:50.327649Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.329853Z","iopub.execute_input":"2023-03-09T06:33:50.330140Z","iopub.status.idle":"2023-03-09T06:33:50.335499Z","shell.execute_reply.started":"2023-03-09T06:33:50.330103Z","shell.execute_reply":"2023-03-09T06:33:50.334564Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<torch.utils.data.dataloader.DataLoader object at 0x7ff2d85cd050>\n","output_type":"stream"}]},{"cell_type":"code","source":"classes = get_classes(\"/kaggle/working/Protocol1_new/Protocol1_seperated/train/\")\nprint(classes, len(classes))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.336995Z","iopub.execute_input":"2023-03-09T06:33:50.337678Z","iopub.status.idle":"2023-03-09T06:33:50.408423Z","shell.execute_reply.started":"2023-03-09T06:33:50.337633Z","shell.execute_reply":"2023-03-09T06:33:50.407650Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"['fake', 'true'] 2\n","output_type":"stream"}]},{"cell_type":"code","source":"dataloaders = {\n    \"train\": train_loader,\n    \"val\": dev_loader\n}\ndataset_sizes = {\n    \"train\": train_data_len,\n    \"val\": dev_data_len\n}","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.409676Z","iopub.execute_input":"2023-03-09T06:33:50.410467Z","iopub.status.idle":"2023-03-09T06:33:50.415046Z","shell.execute_reply.started":"2023-03-09T06:33:50.410423Z","shell.execute_reply":"2023-03-09T06:33:50.414233Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(len(train_loader), len(dev_loader), len(test_loader))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.419260Z","iopub.execute_input":"2023-03-09T06:33:50.419550Z","iopub.status.idle":"2023-03-09T06:33:50.427958Z","shell.execute_reply.started":"2023-03-09T06:33:50.419520Z","shell.execute_reply":"2023-03-09T06:33:50.426853Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"354 565 485\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_data_len, dev_data_len, test_data_len)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.429525Z","iopub.execute_input":"2023-03-09T06:33:50.429841Z","iopub.status.idle":"2023-03-09T06:33:50.437048Z","shell.execute_reply.started":"2023-03-09T06:33:50.429806Z","shell.execute_reply":"2023-03-09T06:33:50.436232Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"5663 9027 7758\n","output_type":"stream"}]},{"cell_type":"code","source":"# now, for the model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.438174Z","iopub.execute_input":"2023-03-09T06:33:50.438584Z","iopub.status.idle":"2023-03-09T06:33:50.509623Z","shell.execute_reply.started":"2023-03-09T06:33:50.438548Z","shell.execute_reply":"2023-03-09T06:33:50.508480Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# model_names = timm.list_models(pretrained=True)\n# print(model_names)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.510992Z","iopub.execute_input":"2023-03-09T06:33:50.511489Z","iopub.status.idle":"2023-03-09T06:33:50.519220Z","shell.execute_reply.started":"2023-03-09T06:33:50.511452Z","shell.execute_reply":"2023-03-09T06:33:50.518485Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"pretrained_model_name = 'deit_base_patch16_224'   #cait_M48 cait_XXS36_224 cait_S24_224 deit_base_distilled_patch16_224 deit_base_patch16_224 deit_tiny_distilled_patch16_224\nno_epochs = 1","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.520714Z","iopub.execute_input":"2023-03-09T06:33:50.521047Z","iopub.status.idle":"2023-03-09T06:33:50.527763Z","shell.execute_reply.started":"2023-03-09T06:33:50.521012Z","shell.execute_reply":"2023-03-09T06:33:50.526997Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\nlearning_rate = 0.03\nmodel = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n\nfor param in model.parameters(): #freeze model\n    param.requires_grad = False\n\nn_inputs = model.head.in_features\nmodel.head = nn.Sequential(\n    \n#     nn.BatchNorm1d(192),\n#     nn.Linear(n_inputs, 512),\n#     nn.ReLU(),\n# #     nn.BatchNorm1d(512),\n#     nn.Dropout(0.2, inplace=True),\n#     nn.Linear(512, 256),\n#     nn.ReLU(),\n#     nn.Dropout(0.2, inplace=True),\n#     nn.Linear(256, 128),\n#     nn.ReLU(),\n#     nn.Dropout(0.2, inplace=True),\n#     nn.Linear(128, 64),\n#     nn.ReLU(),\n# #     nn.Dropout(0.2, inplace=True),\n    \n#     nn.Linear(64, len(classes))\n    ############################################\n    nn.BatchNorm1d(768),\n    nn.Linear(n_inputs, 512),\n    nn.Mish(),\n#     nn.BatchNorm1d(512),\n    nn.Dropout(0.2, inplace=True),\n    nn.Linear(512, 256),\n    nn.Mish(),\n    nn.Dropout(0.2, inplace=True),\n    nn.Linear(256, 128),\n    nn.Mish(),\n    nn.Dropout(0.2, inplace=True),\n    nn.Linear(128, 64),\n    nn.Mish(),\n#     nn.Dropout(0.2, inplace=True),\n    \n    nn.Linear(64, len(classes))\n    ##############################################\n    \n#     nn.BatchNorm1d(192),\n# #     nn.Linear(n_inputs, 512),\n#     nn.PReLU(),\n# #     nn.BatchNorm1d(512),\n#     nn.Dropout(0.2, inplace=True),\n# #     nn.Linear(512, 256),\n#     nn.PReLU(),\n#     nn.Dropout(0.2, inplace=True),\n# #     nn.Linear(256, 128),\n#     nn.PReLU(),\n#     nn.Dropout(0.2, inplace=True),\n# #     nn.Linear(128, 64),\n#     nn.PReLU(),\n    #################################\n#     nn.Linear(n_inputs, 512),\n#     nn.ReLU(),\n#     nn.Dropout(0.3),\n#     nn.Linear(512, len(classes))\n)\n\n# model.head = head_params\nmodel = model.to(device)\n# print(model)\n# parameters\n","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:33:50.529165Z","iopub.execute_input":"2023-03-09T06:33:50.529468Z","iopub.status.idle":"2023-03-09T06:34:16.407914Z","shell.execute_reply.started":"2023-03-09T06:33:50.529428Z","shell.execute_reply":"2023-03-09T06:34:16.407108Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/facebookresearch/deit/archive/main.zip\" to /root/.cache/torch/hub/main.zip\nDownloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/330M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c36fdd45b4cf484d9c5712173d175519"}},"metadata":{}}]},{"cell_type":"code","source":"criterion = LabelSmoothingCrossEntropy()\ncriterion = criterion.to(device)\noptimizer = optim.SGD(model.head.parameters(), lr=learning_rate, momentum=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:34:16.409125Z","iopub.execute_input":"2023-03-09T06:34:16.409414Z","iopub.status.idle":"2023-03-09T06:34:16.415627Z","shell.execute_reply.started":"2023-03-09T06:34:16.409378Z","shell.execute_reply":"2023-03-09T06:34:16.414478Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# lr scheduler\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:34:16.416728Z","iopub.execute_input":"2023-03-09T06:34:16.417318Z","iopub.status.idle":"2023-03-09T06:34:16.428415Z","shell.execute_reply.started":"2023-03-09T06:34:16.417267Z","shell.execute_reply":"2023-03-09T06:34:16.427719Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_accs = []\nval_accs = []\ndef train_model(model, criterion, optimizer, scheduler, num_epochs):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print(\"-\"*10)\n        \n        for phase in ['train', 'val']: # We do training and validation phase per epoch\n            if phase == 'train':\n                model.train() # model to training mode\n            else:\n                model.eval() # model to evaluate\n            \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n                    outputs = model(inputs)\n#                     print(outputs)\n                    _, preds = torch.max(outputs,1) # used for accuracy\n                    loss = criterion(outputs, labels)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n            if phase == 'train':\n                scheduler.step() # step at end of epoch\n            \n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n            \n            if phase == 'val':\n                val_accs.append(epoch_acc)\n            else:\n                train_accs.append(epoch_acc)\n            \n            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n            \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n        print()\n    time_elapsed = time.time() - since # slight error\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n    \n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:34:16.429842Z","iopub.execute_input":"2023-03-09T06:34:16.430097Z","iopub.status.idle":"2023-03-09T06:34:16.443169Z","shell.execute_reply.started":"2023-03-09T06:34:16.430064Z","shell.execute_reply":"2023-03-09T06:34:16.442470Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler,num_epochs=no_epochs) \n","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:34:16.444175Z","iopub.execute_input":"2023-03-09T06:34:16.445036Z","iopub.status.idle":"2023-03-09T06:36:04.735445Z","shell.execute_reply.started":"2023-03-09T06:34:16.445001Z","shell.execute_reply":"2023-03-09T06:36:04.734594Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 0/0\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 354/354 [00:45<00:00,  7.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.6105 Acc: 0.6917\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 565/565 [01:02<00:00,  9.03it/s]","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.4201 Acc: 0.8703\n\nTraining complete in 1m 48s\nBest Val Acc: 0.8703\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"x = [i for i in range(no_epochs)]\n# plot lines\nplt.plot(x, train_accs, label = \"Training Accuracy\")\nplt.plot(x, val_accs, label = \"Validation Accuracy\")\nplt.xlabel(\"Epoch Number\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:36:04.737575Z","iopub.execute_input":"2023-03-09T06:36:04.738104Z","iopub.status.idle":"2023-03-09T06:36:04.988302Z","shell.execute_reply.started":"2023-03-09T06:36:04.738057Z","shell.execute_reply":"2023-03-09T06:36:04.987483Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"dev_loss = 0.0\nclass_correct = list(0 for i in range(len(classes)))\nclass_total = list(0 for i in range(len(classes)))\nmodel_ft.eval()\ndev_predictions = []\ndev_targets = []\n\nfor data, target in tqdm(dev_loader):\n    data, target = data.to(device), target.to(device)\n    with torch.no_grad(): # turn off autograd for faster testing\n        output = model_ft(data)\n        loss = criterion(output, target)\n    dev_loss = loss.item() * data.size(0)\n    _, pred = torch.max(output, 1)\n    pred_list = np.squeeze(pred.cpu().numpy())\n    target_list = np.squeeze(target.cpu().numpy())\n    dev_predictions.extend(pred_list)\n    dev_targets.extend(target_list)\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.cpu().numpy())\n#     print('target',target)\n#     print('##################################################')\n#     print('output',output)\n#     print('##################################################')\n#     print('pred',pred)\n#     print('##################################################')\n#     print('correct_tensor',correct_tensor)\n#     print('##################################################')\n#     print('correct',correct)\n    if len(target) == 32:\n        for i in range(32):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\n# print('class_correct',class_correct)\n# print('##################################################')\n# print('class_total',class_total)\n\ndev_loss = dev_loss / dev_data_len\nprint('Dev Loss: {:.4f}'.format(dev_loss))\nfor i in range(len(classes)):\n    if class_total[i] > 0:\n        print(\"Dev Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n        ))\n    else:\n        print(\"Dev accuracy of %5s: NA\" % (classes[i]))\nprint(\"Dev Accuracy of %2d%% (%2d/%2d)\" % (\n            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n        ))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:36:04.989750Z","iopub.execute_input":"2023-03-09T06:36:04.990489Z","iopub.status.idle":"2023-03-09T06:37:07.398676Z","shell.execute_reply.started":"2023-03-09T06:36:04.990452Z","shell.execute_reply":"2023-03-09T06:37:07.397010Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"100%|██████████| 565/565 [01:02<00:00,  9.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dev Loss: 0.0001\nDev accuracy of  fake: NA\nDev accuracy of  true: NA\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/1570156687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dev accuracy of %5s: NA\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m print(\"Dev Accuracy of %2d%% (%2d/%2d)\" % (\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         ))\n","\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"],"ename":"ValueError","evalue":"cannot convert float NaN to integer","output_type":"error"}]},{"cell_type":"code","source":"test_loss = 0.0\nclass_correct = list(0 for i in range(len(classes)))\nclass_total = list(0 for i in range(len(classes)))\nmodel_ft.eval()\ntest_predictions = []\ntest_targets = []\n\nfor data, target in tqdm(test_loader):\n    data, target = data.to(device), target.to(device)\n    with torch.no_grad(): # turn off autograd for faster testing\n        output = model_ft(data)\n        loss = criterion(output, target)\n    test_loss = loss.item() * data.size(0)\n    _, pred = torch.max(output, 1)\n    pred_list = np.squeeze(pred.cpu().numpy())\n    target_list = np.squeeze(target.cpu().numpy())\n    test_predictions.extend(pred_list)\n    test_targets.extend(target_list)\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.cpu().numpy())\n#     print('target',target)\n#     print('##################################################')\n#     print('output',output)\n#     print('##################################################')\n#     print('pred',pred)\n#     print('##################################################')\n#     print('correct_tensor',correct_tensor)\n#     print('##################################################')\n#     print('correct',correct)\n    if len(target) == 32:\n        for i in range(32):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\n# print('class_correct',class_correct)\n# print('##################################################')\n# print('class_total',class_total)\n\ntest_loss = test_loss / test_data_len\nprint('Test Loss: {:.4f}'.format(test_loss))\nfor i in range(len(classes)):\n    if class_total[i] > 0:\n        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n        ))\n    else:\n        print(\"Test accuracy of %5s: NA\" % (classes[i]))\nprint(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n        ))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.400968Z","iopub.status.idle":"2023-03-09T06:37:07.401286Z","shell.execute_reply.started":"2023-03-09T06:37:07.401115Z","shell.execute_reply":"2023-03-09T06:37:07.401139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('Target Labels: ',len(targets))\n# print('Prediction Labels: ',len(predictions))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.402444Z","iopub.status.idle":"2023-03-09T06:37:07.403014Z","shell.execute_reply.started":"2023-03-09T06:37:07.402778Z","shell.execute_reply":"2023-03-09T06:37:07.402804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EER\ndef compute_eer(label, pred, positive_label=1):\n    # all fpr, tpr, fnr, fnr, threshold are lists (in the format of np.array)\n    fpr, tpr, threshold = sklearn.metrics.roc_curve(label, pred, positive_label)\n    fnr = 1 - tpr\n\n    # the threshold of fnr == fpr\n    eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n\n    # theoretically eer from fpr and eer from fnr should be identical but they can be slightly differ in reality\n    eer_1 = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n    eer_2 = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n\n    # return the mean of eer from fpr and from fnr\n    eer = (eer_1 + eer_2) / 2\n   \n    return eer\n\ntest_EER = compute_eer(test_targets,test_predictions)\ndev_EER = compute_eer(dev_targets,dev_predictions)\n\nprint('The EER for Dev is: {:.2f}'.format(dev_EER))\nprint('The EER for Test is: {:.2f}'.format(test_EER))","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.404667Z","iopub.status.idle":"2023-03-09T06:37:07.405137Z","shell.execute_reply.started":"2023-03-09T06:37:07.404897Z","shell.execute_reply":"2023-03-09T06:37:07.404921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HTER\ndef calculate_HTER(y_true, y_pred):\n    cm = confusion_matrix(y_true, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n    far = fp / (fp + tn)\n    frr = fn / (tp + fn)\n    hter = (far + frr) / 2\n    return hter\n\n\ndev_hter = calculate_HTER(dev_targets, dev_predictions)\nprint('The HTER for Dev is: {:.2f}'.format(dev_hter))\n\ntest_hter = calculate_HTER(test_targets, test_predictions)\nprint('The HTER for Test is: {:.2f}'.format(test_hter))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.406813Z","iopub.status.idle":"2023-03-09T06:37:07.407227Z","shell.execute_reply.started":"2023-03-09T06:37:07.407002Z","shell.execute_reply":"2023-03-09T06:37:07.407024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = torch.rand(1, 3, 224, 224)\ntraced_script_module = torch.jit.trace(model.cpu(), example)\ntraced_script_module.save(\"protocol1_model.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.408659Z","iopub.status.idle":"2023-03-09T06:37:07.409111Z","shell.execute_reply.started":"2023-03-09T06:37:07.408870Z","shell.execute_reply":"2023-03-09T06:37:07.408899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#APCER, BPCER, ACER\ntest_attack_types = [ (1 if x==1 else 2) for x in test_targets]\ndev_attack_types = [ (1 if x==1 else 2) for x in dev_targets]\n\n\n# returns the metrics APCER, BPCER and ACER\ntest_apcer, test_bpcer, test_acer = oulumetrics.calculate_metrics(test_attack_types, test_predictions)\ndev_apcer, dev_bpcer, dev_acer = oulumetrics.calculate_metrics(dev_attack_types, dev_predictions)\n\nprint('######## Dev Oulu Metrics ##########')\nprint('APCER: {:.2f}'.format(dev_apcer))\nprint('BPCER: {:.2f}'.format(dev_bpcer))\nprint('ACER: {:.2f}'.format(dev_acer))\n\nprint('######## Test Oulu Metrics ##########')\nprint('APCER: {:.2f}'.format(test_apcer))\nprint('BPCER: {:.2f}'.format(test_bpcer))\nprint('ACER: {:.2f}'.format(test_acer))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.410296Z","iopub.status.idle":"2023-03-09T06:37:07.411151Z","shell.execute_reply.started":"2023-03-09T06:37:07.410907Z","shell.execute_reply":"2023-03-09T06:37:07.410933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pillow\nfrom PIL import Image\n","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.412708Z","iopub.status.idle":"2023-03-09T06:37:07.413180Z","shell.execute_reply.started":"2023-03-09T06:37:07.412898Z","shell.execute_reply":"2023-03-09T06:37:07.412925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# transform = T.Compose([\n#             T.RandomHorizontalFlip(),\n#             T.RandomVerticalFlip(),\n# #             T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.25),\n#             T.Resize(256),\n#             T.CenterCrop(224),\n#             T.ToTensor(),\n#             T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # imagenet means\n#             T.RandomErasing(p=0.20, value='random')\n#         ])\n\n# img = Image.open(\"/kaggle/working/undersampled_protocol1/train_undersampled/true/1_1_01_1_001_rgb.jpg\")\n# img_tensor = transform(img).unsqueeze(0)  # add a batch dimension\n\n# with torch.no_grad():\n#     features = model.forward_features(img_tensor).squeeze()  # remove the batch dimension\n\n# print(features.shape)\n# print(features)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.414683Z","iopub.status.idle":"2023-03-09T06:37:07.415279Z","shell.execute_reply.started":"2023-03-09T06:37:07.415035Z","shell.execute_reply":"2023-03-09T06:37:07.415058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model_ft.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:46:37.651434Z","iopub.execute_input":"2023-03-09T06:46:37.651767Z","iopub.status.idle":"2023-03-09T06:46:37.660545Z","shell.execute_reply.started":"2023-03-09T06:46:37.651731Z","shell.execute_reply":"2023-03-09T06:46:37.659854Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"features = []\nlabels_array = []\n\nwith torch.no_grad():\n    for images, labels in tqdm(train_loader):\n        images = images.to(device)\n        # Pass the images through the DeiT model to obtain the features\n        outputs = model.forward_features(images)\n        # Reshape the output tensor to (batch_size, num_features)\n        features.append(outputs.view(outputs.size(0), -1).cpu().numpy())\n        labels_array.append(labels.numpy())\n\n# Concatenate the features into a single numpy array\nfeatures = np.concatenate(features, axis=0)\n# Concatenate the labels into a single numpy array\nlabels_array = np.concatenate(labels_array).flatten()\nx_train = pd.DataFrame(features)\ny_train = pd.DataFrame(labels_array)\nx_train.to_csv('x_train.csv', index=False)\ny_train.to_csv('y_train.csv', index=False)\nprint(x_train.shape,y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:46:41.098778Z","iopub.execute_input":"2023-03-09T06:46:41.099045Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"100%|██████████| 354/354 [00:42<00:00,  8.41it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"features = []\nlabels_array = []\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader):\n        images = images.to(device)\n        # Pass the images through the DeiT model to obtain the features\n        outputs = model.forward_features(images)\n        # Reshape the output tensor to (batch_size, num_features)\n        features.append(outputs.view(outputs.size(0), -1).cpu().numpy())\n        labels_array.append(labels.numpy())\n\n# Concatenate the features into a single numpy array\nfeatures = np.concatenate(features, axis=0)\n# Concatenate the labels into a single numpy array\nlabels_array = np.concatenate(labels_array).flatten()\nx_test = pd.DataFrame(features)\ny_test = pd.DataFrame(labels_array)\nprint(x_test.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.420575Z","iopub.status.idle":"2023-03-09T06:37:07.421042Z","shell.execute_reply.started":"2023-03-09T06:37:07.420813Z","shell.execute_reply":"2023-03-09T06:37:07.420836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = []\nlabels_array = []\nwith torch.no_grad():\n    for images, labels in tqdm(dev_loader):\n        images = images.to(device)\n        # Pass the images through the DeiT model to obtain the features\n        outputs = model.forward_features(images)\n        # Reshape the output tensor to (batch_size, num_features)\n        features.append(outputs.view(outputs.size(0), -1).cpu().numpy())\n        labels_array.append(labels.numpy())\n\n# Concatenate the features into a single numpy array\nfeatures = np.concatenate(features, axis=0)\n# Concatenate the labels into a single numpy array\nlabels_array = np.concatenate(labels_array).flatten()\nx_dev = pd.DataFrame(features)\ny_dev = pd.DataFrame(labels_array)\nprint(x_dev.shape,y_dev.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.422357Z","iopub.status.idle":"2023-03-09T06:37:07.422852Z","shell.execute_reply.started":"2023-03-09T06:37:07.422605Z","shell.execute_reply":"2023-03-09T06:37:07.422643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\n# Create an XGBRegressor model\nmodel = xgb.XGBRegressor()\n\n# Define the hyperparameters to search over\nparam_grid = {\n     'n_estimators': [100, 500, 1000],\n     \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] \n}\n\n# Create a grid search object\ngrid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1)\n\n# Fit the grid search object to the development data\ngrid_search.fit(X_dev, y_dev)\n\n# Print the best hyperparameters and the corresponding mean test score\nprint(f'Best hyperparameters: {grid_search.best_params_}')\nprint(f'Best mean test score: {grid_search.best_score_}')\n\n# Train the model with the best hyperparameters on the combined train/dev set\nbest_model = xgb.XGBRegressor(**grid_search.best_params_)\nbest_model.fit(x_train, y_train)\n\n# Evaluate the best model on the test set\ntest_score = best_model.score(X_test, y_test)\nprint(f'Test score: {test_score}')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.423978Z","iopub.status.idle":"2023-03-09T06:37:07.424550Z","shell.execute_reply.started":"2023-03-09T06:37:07.424296Z","shell.execute_reply":"2023-03-09T06:37:07.424321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = best_model.predict(x_test)\ny_actual = y_test","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.426150Z","iopub.status.idle":"2023-03-09T06:37:07.426716Z","shell.execute_reply.started":"2023-03-09T06:37:07.426468Z","shell.execute_reply":"2023-03-09T06:37:07.426491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_actual, y_pred)\nf1 = f1_score(y_actual, y_pred)\ncm = confusion_matrix(y_actual, y_pred)\n\n# Print the results\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(f\"F1 score: {f1:.2f}\")\nprint(\"Confusion matrix:\")\nprint(cm)\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-09T06:37:07.430143Z","iopub.status.idle":"2023-03-09T06:37:07.430810Z","shell.execute_reply.started":"2023-03-09T06:37:07.430545Z","shell.execute_reply":"2023-03-09T06:37:07.430570Z"},"trusted":true},"execution_count":null,"outputs":[]}]}